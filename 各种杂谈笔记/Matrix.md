create_time: 2021年05月07日

[TOC]

## 一、矩阵类型

### 1、方阵

#### 1.1、行列式

并不是所有矩阵都有行列式的概念的，只有方阵有行列式

#### 1.2、逆矩阵

只有方阵才有逆矩阵的，$AA^T=I$

#### 1.1、特征值分解

只有方阵才可以做特征值分解，$A=X\Lambda X^{-1}$，其中X是正交矩阵

所有方阵都可以做特征值分解吗？

> 不是的，要方阵A可以做特征值分解的充要条件是其有n个线性无关的特征向量

### 2、对称矩阵

为什么对称矩阵那么特殊？我想可以和**二次型**关联起来，二次型很重要，二次型的矩阵是个对称阵。

> （1）二次型很重要，在书籍中甚至可以单独成为一个章节？
>
> 什么是二次型？每个项的次数都是2次，例如$x_1^2+2x_1x_2+...+2x_1x_n+x_2^2+...$，对应的矩阵是对称阵A，二次型可以写成$X'AX$
>
> （2）为什么只讨论二次型？有没有三次型？四次型？...
>
> 也是有的（对应的不再是矩阵，是个张量了）先从简单的讨论，高阶万变不离其宗的



#### 2.1、实对称矩阵一定可以对角化

实对称矩阵一定可以对角化

$A = Q \Lambda Q^{-1} = Q \Lambda Q^T$

其中Q是特征向量构成的正交矩阵，$\Lambda$是特征值组成的对角阵

> 因为A是对角矩阵，$A^T=A$
>
> $A^T = (X \Lambda X^{-1})^T = (X^{-1})^T\Lambda X^T$
>
> 即$X^{-1}=X^T$，可以推出$X^TX=I$，即此时获取的特征向量之间是标准正交的
>
> 正交矩阵的符号$Q$，满足$Q^{-1}=Q^T$，因此对称矩阵可以分解为$Q \Lambda Q^{-1}$

【暂放】为什么是**一定**可以？



#### 2.2、若两个实对称矩阵是相似的，那么他们肯定合同

蛮特别的

因为实对称矩阵一定存在正交转换Q

所以如果是相似的，那么肯定是合同的

#### 2.2、正定性

矩阵的正定型广义定义是满足$z^TAz>0$的矩阵，但狭义定义要求矩阵A是对称矩阵。

> 前面提到对称矩阵和二次型关联起来的，满足$z^TAz>0$的二次型是一个开口朝上的曲线，所有值都大于0
>
> ![](https://pic4.zhimg.com/80/v2-ebdfb7c7510ac85a582d6e79c1ef37b3_720w.jpg)

正定性的判断可以根据（1）顺序主子式是否都大于0；（2）特征值



#### 2.3、化标准型和规范型

实数域上的n元二次型$X'AX = x_1^2+2x_1x_2+...+2x_1x_n+x_2^2+...$有一个标准形为

$Y'\Lambda Y= \lambda_1y_1^2+\lambda_2y_2^2+...+\lambda_ny_n^2$

> 计算方法：$|\lambda E- A|$求出特征值，得到对应的特征向量（不唯一的）

二次型的标准形不唯一，规范型才是唯一的$z_1^2+z_2^2+...+z_n^2$（系数只可以为1或者-1）



### 3、正交矩阵

如果$AA^T=I$，则方阵A是正交矩阵

![img](https://pic4.zhimg.com/v2-b3229a85dbcb73299c3a88c030184673_b.jpg)

> （1）因为$AA^{-1}=I$，所以正交矩阵的逆等于转置$A^T=A^{-1}$
>
> （2）等式两边求行列式，可以得到正交矩阵的行列式值为1或-1

正交——垂直

标准正交

正交矩阵一定可以对角化



## 二、矩阵性质

### 1、矩阵正定性

在线性代数中，正定矩阵的性质类似复数中的正实数

> 就像在自然数里有正数，负数，0，整数（0和正数）等概念
>
> 在矩阵的大集合里，也有正定矩阵（对应正数），负定矩阵（对应负数）、半正定矩阵（对应整数）



#### 1.1、正定矩阵定义

广义定义：设M是n阶方阵，如果对任何非零向量z，都有$z^TMz>0$，其中$z^T$表示z的转置，就称M为正定矩阵。

狭义定义：一个n阶的实对称矩阵M是正定的的条件是当且仅当对于所有的非零实系数向量z，都有$z^TMz>0$。其中$z^T$表示z的转置。

>  广义定义和狭义定义的差异：狭义要求矩阵M是实对称矩阵
>
> 不过归根到底就是任意非零向量和矩阵M做$z^TMz$的处理后结果都要大于0的



[关于正定矩阵变换程度的理解](<https://www.zhihu.com/question/304499772/answer/552481133>)给出了矩阵正定的另一种理解：任意非零向量$X^TAX$可以理解为$X^T(AX)$

把A看作已经选定的基下的线性变换，那么AX就是经过线性变换后的向量

二次型正定就表明原来的向量X与变换后的向量点乘恒大于0，点乘恒大于0说明夹角小于90度，**一定程度上反映了这个A代表的线性变换对向量的改变不大。**

> 行列式值的几何意义：同维度上变化的大小（二维是变化发生的面积，三维是变化发生的体积，...）
>
> 行列式大于0一定程度上反映了线性变换变化较小，即在每个维度(维度小于整个线性空间的维度n)上变化都很小
>
> 行列式小于0说明该变换相当于整个空间都被翻转了！这个变化天翻地覆
>
> 非方阵矩阵没有行列式的概念，因为维度不同无法比较。

如果A是正定的，向量X与AX的点乘恒大于0，说明两个向量变化不大，由于行列式可以反应变化，即行列式上任意维度的行列式值都要大于0，由此可以理解为什么可以用顺序主子式的方法判断矩阵是否正定。



#### 1.2、如何判断矩阵的正定性

根据正定矩阵的定义及性质，判别对称矩阵A的正定性有两种方法：

（1）求出A的所有特征值。若A的特征值均为正数，则A是正定的；若A的特征值均为负数，则A为负定的。

（2）计算A的各阶主子式。若A的各阶主子式均大于零，则A是正定的；若A的各阶主子式中，奇数阶主子式为负，偶数阶为正，则A为负定的。

对于具体的实对称矩阵，常用矩阵的各阶顺序主子式是否大于零来判断其正定性；

对于抽象的矩阵，由给定矩阵的正定性，利用标准型，特征值及充分必要条件来证相关矩阵的正定性



#### 1.3、Hessian矩阵的正定性与梯度下降

矩阵正定性的判断及Hessian矩阵正定性在梯度下降中的应用

在牛顿法等梯度下降的方法中,Hessian矩阵的正定性可以很容易的判断函数是否可收敛到局部或全局最优解。

牛顿法解决优化问题中，hessian矩阵是负定，非定，正定时的原函数曲线

![<https://blog.csdn.net/itnerd/article/details/100519962>](https://img-blog.csdnimg.cn/20190903154415528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0bmVyZA==,size_16,color_FFFFFF,t_70)

所以当hessian矩阵为正定时，梯度下降有极小值



## 三、矩阵的分解

### 1、特征值分解对角化

只有方阵才可以做特征值分解，$A=X\Lambda X^{-1}$，其中X是正交矩阵

### 2、LU分解

判断方阵A是否可以进行唯一LU分解

若矩阵A的各阶顺序主子式不等于0（矩阵正定），则A可以进行唯一的LU分解

L为单位下三角矩阵，U为上三角矩阵

![](https://img-blog.csdn.net/20171117113045370)



## 四、矩阵关系

矩阵的关系：等价、相似与合同

### 1、定义角度

![](https://pic1.zhimg.com/v2-37a905dc59f8d7795e25f9c68270e7d4_b.jpg)

分别是什么？怎么理解？强弱程度是怎样的？

**等价**：矩阵之间可以通过初等变换得到，且是可逆的（A可以通过初等变换得到B，B也可以通过逆的初等变换得到A）

等价关系是最弱的，两个矩阵相似或者合 同，那么这两个矩阵一定等价。相似与合同矩阵之间没有必然的联系，不能能够互相推导

![](https://pic1.zhimg.com/v2-b8ba32f5303ec58c4c88d6f1be1bfbd0_b.jpg)

相交部分是正交矩阵$P^{-1} = P^T$

由于实对称矩阵一定有正交矩阵P，所以若两个实对称矩阵是相似的，那么他们肯定合同

### 2、矩阵性质角度

等价（只有秩相同）–>合同（秩和正负惯性指数相同）–>相似（秩，正负惯性指数，特征值均相同），矩阵亲密关系的一步步深化

[爹说爹有理，娘说娘有理，所以关系到底是怎样的呢？](<https://www.zhihu.com/search?type=content&q=%E7%AD%89%E4%BB%B7%E7%9B%B8%E4%BC%BC%E5%90%88%E5%90%8C>)

把所有相似的矩阵都给我放到一块，它们里面随便拿哪个出来都可以作为这一个类的代表，那我们当然就想找一个看着养眼（比较漂亮(๑> <๑））的矩阵来代表这个类啦

这个比较漂亮的矩阵就叫标准型，我们加上修饰语“相似”，就变成了相似标准型，没错，它就是我们早就知道的若尔当标准型。一个类里的矩阵必然有很多共性（不是一家人，不进一家门嘛），因此迹啊，特征值啊，不变因子啊…很多东西都是相等的，这些叫作这个等价关系下的不变量。如果我们把这些不变量找全（或者其中起决定性的某几个不变量）了，那么根据不变量就能轻松识别哪些矩阵是相似的了

合同等价于正负惯性指数相同，正负惯性指数的符号即为特征值的符号

所以总结一下，对对称矩阵而言，相似 => 合同 => 等价。对一般矩阵而言，相似和合同无必然联系

青岛考研学长：https://zhuanlan.zhihu.com/p/325741673


### 3、线性变换角度

矩阵相似：$P^{-1}AP=B$；针对方阵而言；秩相等为必要条件；本质是二者有相等的不变因子；可看作是同一线性变换在不同基下的矩阵；矩阵相似必等价，但等价不一定相似；

 



为什么高斯核能够拟合无穷维度

因为将泰勒展开式代入高斯核,将会得到一个无穷维度的映射。

<https://www.nowcoder.com/ta/review-ml/review?tpId=96&tqId=32484&query=&asc=true&order=&page=53>





## 参考资料

[1] 力扣—黑塞矩阵的正定性与梯度下降关系：<https://www.nowcoder.com/ta/review-ml/review?tpId=96&tqId=32450&query=&asc=true&order=&page=19>



## 附录

### 1、n阶顺序主子式

矩阵A的顺序主子式由n个行列式按顺序排列而成，从左上角依次往下生成对应的i阶行列式，最后生成矩阵A的顺序主子式集合。

> 例如：
>
> ![<https://baike.baidu.com/item/%E9%A1%BA%E5%BA%8F%E4%B8%BB%E5%AD%90%E5%BC%8F/3167642?fr=aladdin>](/home/shi3761/Desktop/baseMath/images/顺序主子式例子.png)

[关于顺序主子式维度的理解](<https://www.zhihu.com/question/304499772/answer/552481133>)

我们把行列式看做矩阵A带来的变换(二维上是面积、三维上是体积、...)

一个矩阵的顺序主子式即依次考察一维、二维、三维、...带来的变换。



### 2、hessian矩阵

#### 2.1、什么是hessian矩阵？

黑塞矩阵（海森矩阵，二阶导数矩阵）

![1620371710104](/home/shi3761/Desktop/baseMath/images/hessian_matrix.png)



#### 2.2、黑塞矩阵与多元函数的极值问题

设n多元实函数$f(x_1,x_2,...,x_n)$在点$X_0$的邻域内有二阶连续偏导，对应的矩阵A是一个hessian矩阵。

（1）当A正定矩阵时，  即二阶导数大于0，在$X_0$处是极小值；
（2）当A负定矩阵时，  在$X_0$处是极大值；
（3）当A不定矩阵时，  不是极值点。
（4）当A为半正定矩阵或半负定矩阵时，  是“可疑”极值点，尚需要利用其他方法来判定



#### 2.3、hessian矩阵与泰勒展开式

（1）若一元函数f(x)在$x_0$有任意阶导，则f(x)在该点的泰勒展开式为

$f(x) = f(x_0) + f'(x_0)(x-x_0) + \frac{f''(x_0)}{2!}(x-x_0)^2+...$

（2）二元函数$f(x,y)$在$(x_0,y_0)$有任意阶导，则f(x,y)在该点的泰勒展开式为

![img](/home/shi3761/Desktop/baseMath/images/%E4%BA%8C%E5%85%83%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E5%BC%8F.svg)

`出现了2阶的黑塞矩阵了`

（3）n元函数$f(x_1,x_2,...,x_n)$在某一点的泰勒展开式

![img](/home/shi3761/Desktop/baseMath/images/n%E5%85%83%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E5%BC%8F.svg)

其中

![img](/home/shi3761/Desktop/baseMath/images/%E4%B8%80%E9%98%B6%E5%81%8F%E5%AF%BC.svg)

![img](/home/shi3761/Desktop/baseMath/%E5%A4%9A%E5%85%83%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E7%9A%84%E9%BB%91%E5%A1%9E%E7%9F%A9%E9%98%B5.svg)

`在二阶求导的时候出现黑塞矩阵`



#### 2.4、hessian矩阵与梯度下降的联系

牛顿法是梯度下降的其中一种方法之一。

牛顿法中损失函数做二阶泰勒展开

> $f(x) \approx f(x_0)+f'(x_0)+\frac{f''(x_0)}{2!}(x-x_0)^2$
>
> 相应的导数近似为
>
> $\frac{ df(x)}{d\Delta{x}}  \approx f'(x_n)+ f''(x_n)\Delta{x}$

一阶导数等于0得到极值点

> $f'(x_n)+ f''(x_n)\Delta{x}  = 0$
>
> 梯度想讲的步幅 $\Delta{x} = -\frac{f'(x_n)}{f''(x_n)}$
>
> $x_{n+1}  = x_n +  \Delta{x} = x_n -\frac{f'(x_n)}{f''(x_n)} =x_{n} -[H f(x_{n})]^{-1} f'(x_{n})$

此时牛顿法梯度下降的步幅就和hessian矩阵关联起来了

学习率与曲率成反比，也就是说在曲率大的方向的学习率小，而在曲率小的方向的学习率大。也就是是说此时的梯度下降在顺流而下的方向的学习率更大，也就更快收敛了。



### 3、二阶导数与原函数的关系

函数导数和极值点的关系

| $f'(x)$   | $f''(x)$   | $f(x)$         |
| --------- | ---------- | -------------- |
| $f'(x)=0$ | $f''(x)>0$ | 局部最小值     |
| $f'(x)=0$ | $f''(x)<0$ | 局部最大值     |
| $f'(x)=0$ | $f''(x)=0$ | 局部极值或鞍点 |

一阶导数衡量梯度，二阶导数衡量曲率（curvature）。

当 $f''(x)<0$， $f(x)$ 往上弯曲；当 $f''(x)>0$时，$f(x)$ 往下弯曲

![<https://blog.csdn.net/zhangchen124/article/details/105004738/>](/home/shi3761/Desktop/baseMath/images/原函数与一阶二阶导数的关系.png)

### 4、向量的乘积值与变化

两个向量XY，点乘$X^TY$恒大于0说明夹角小于90度，**一定程度上反映了两个向量的改变不大。**

> 比如
>
> （1）$X= \left[ \begin{matrix} 1\\2\end{matrix} \right]$，$Y= \left[ \begin{matrix} 1\\1\end{matrix} \right]$，是从原点出发第一象限的两个向量，点乘$X^TY=1+2=3>0$，此时向量夹角小于90度
>
> （2）$X= \left[ \begin{matrix} 1\\2\end{matrix} \right]$，$Y= \left[ \begin{matrix} -1\\1\end{matrix} \right]$，点乘$X^TY=-1+2=1>0$，此时向量夹角小于90度
>
> （2）$X= \left[ \begin{matrix} 1\\2\end{matrix} \right]$，$Y= \left[ \begin{matrix} -1\\-1\end{matrix} \right]$，点乘$X^TY=-1-2=-3$，此时向量夹角大于90度
>
> （2）$X= \left[ \begin{matrix} 1\\2\end{matrix} \right]$，$Y= \left[ \begin{matrix} 1\\-1\end{matrix} \right]$，点乘$X^TY=1-2=-1$，此时向量夹角大于90度
>
> 及点乘的正负和两个向量的夹角有关

### 5、线性变换：退化、非退化



### 6、经常看到的组合

#### 6.1、$X'AX$

正定矩阵：一个n阶的实对称矩阵M是正定的的条件是当且仅当对于所有的非零实系数向量z，都有$X^TAX>0$

矩阵相似/合同

二次型可以写成$X'AX$



#### 6.2、$X^{-1}AX$

对角化： $A = Q \Lambda Q^{-1}$

## 